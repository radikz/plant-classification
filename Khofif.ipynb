{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "189e6799-50e5-4c59-8e00-402d57c638f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  rice"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\", delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b6e12-a454-4698-86b1-18822ec8efb1",
   "metadata": {},
   "source": [
    "## Mencari jumlah tiap label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce7be58a-aef3-4567-af4a-f59d6e48d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rice</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soyabeans</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beans</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cowpeas</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orange</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maize</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>peas</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>groundnuts</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mango</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>watermelon</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grapes</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>apple</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cotton</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label  Total\n",
       "0         rice    139\n",
       "1    Soyabeans    130\n",
       "2       banana    130\n",
       "3        beans    125\n",
       "4      cowpeas    122\n",
       "5       orange    122\n",
       "6        maize    119\n",
       "7       coffee    110\n",
       "8         peas    100\n",
       "9   groundnuts    100\n",
       "10       mango    100\n",
       "11  watermelon    100\n",
       "12      grapes    100\n",
       "13       apple    100\n",
       "14      cotton    100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = df['label'].value_counts().reset_index()\n",
    "label_counts.columns = ['Label', 'Total']\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be09bdc-4941-4091-a21f-b7f720d45df1",
   "metadata": {},
   "source": [
    "## Membagi data menjadi 2/3 data training dan sisa nya akan masuk ke data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa9f2b3-cf76-46f0-b903-a53aa30d4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training\n",
      "label\n",
      "rice          92\n",
      "Soyabeans     86\n",
      "banana        86\n",
      "beans         83\n",
      "cowpeas       81\n",
      "orange        81\n",
      "maize         79\n",
      "coffee        73\n",
      "peas          66\n",
      "groundnuts    66\n",
      "mango         66\n",
      "watermelon    66\n",
      "grapes        66\n",
      "apple         66\n",
      "cotton        66\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "Data Testing\n",
      "label\n",
      "rice          47\n",
      "Soyabeans     44\n",
      "banana        44\n",
      "beans         42\n",
      "cowpeas       41\n",
      "orange        41\n",
      "maize         40\n",
      "coffee        37\n",
      "peas          34\n",
      "groundnuts    34\n",
      "mango         34\n",
      "watermelon    34\n",
      "grapes        34\n",
      "apple         34\n",
      "cotton        34\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    train, test = train_test_split(subset, test_size=1/3, random_state=42, stratify=None)\n",
    "    train_data = pd.concat([train_data, train])\n",
    "    test_data = pd.concat([test_data, test])\n",
    "\n",
    "print('Data Training')\n",
    "print(train_data['label'].value_counts())\n",
    "print(\"----------------------------------\")\n",
    "print('Data Testing')\n",
    "print(test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e2a2a-4782-45f9-8e3d-b11b80bdc6b6",
   "metadata": {},
   "source": [
    "Training data dengan membentuk 100 pohon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48194737-6519-4b50-9126-60c0680e3b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Features and target\n",
    "features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph']\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d8d7591-ea5c-4273-b24f-873b79cd1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9860627177700348\n",
      "Precision (macro): 0.9850292397660818\n",
      "Recall (macro): 0.9843137254901961\n",
      "F1 Score (macro): 0.9842592592592593\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", test_acc)\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca667374-6da6-4a15-882e-c9de68d9492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Laporan klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Soyabeans       1.00      1.00      1.00        44\n",
      "       apple       1.00      1.00      1.00        34\n",
      "      banana       1.00      1.00      1.00        44\n",
      "       beans       1.00      1.00      1.00        42\n",
      "      coffee       1.00      1.00      1.00        37\n",
      "      cotton       1.00      1.00      1.00        34\n",
      "     cowpeas       1.00      1.00      1.00        41\n",
      "      grapes       1.00      1.00      1.00        34\n",
      "  groundnuts       0.84      0.94      0.89        34\n",
      "       maize       1.00      1.00      1.00        40\n",
      "       mango       1.00      1.00      1.00        34\n",
      "      orange       1.00      1.00      1.00        41\n",
      "        peas       0.93      0.82      0.88        34\n",
      "        rice       1.00      1.00      1.00        47\n",
      "  watermelon       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.99       574\n",
      "   macro avg       0.99      0.98      0.98       574\n",
      "weighted avg       0.99      0.99      0.99       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLaporan klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11c148-0f65-4d4a-979f-5e3479c0957b",
   "metadata": {},
   "source": [
    "## Understanding Precision, Recall, and F1-Score\n",
    "\n",
    "Let's break down the use and interpretation of precision, recall, and the F1-score in the context of your classification model.\n",
    "\n",
    "### Understanding the Basics with a Confusion Matrix\n",
    "\n",
    "Imagine your random forest model is trying to predict whether a plant is 'rice' or 'not rice'. We can summarize the model's performance for the 'rice' class using a confusion matrix:\n",
    "\n",
    "|                    | Predicted: Rice | Predicted: Not Rice |\n",
    "| :----------------- | :-------------- | :------------------ |\n",
    "| **Actual: Rice** | True Positive (TP) | False Negative (FN) |\n",
    "| **Actual: Not Rice** | False Positive (FP) | True Negative (TN)  |\n",
    "\n",
    "* **True Positive (TP):** The model correctly predicted 'rice', and it actually was 'rice'.\n",
    "* **False Positive (FP):** The model incorrectly predicted 'rice', but it was actually 'not rice'. (Also known as a Type I error).\n",
    "* **False Negative (FN):** The model incorrectly predicted 'not rice', but it was actually 'rice'. (Also known as a Type II error).\n",
    "* **True Negative (TN):** The model correctly predicted 'not rice', and it actually was 'not rice'.\n",
    "\n",
    "### 1. Precision: \"Of all the plants the model said were rice, how many actually were?\"\n",
    "\n",
    "* **Formula:** $\\text{Precision} = \\frac{TP}{TP + FP}$\n",
    "* **Usefulness:** Precision is useful when you want to minimize **false positives**. In other words, when you want to be very sure that if the model predicts a certain class, it's highly likely to be correct.\n",
    "* **Interpretation:**\n",
    "    * A **high precision** (closer to 1.0) means that when the model predicts a plant is 'rice', it is very often correct. There aren't many instances where it incorrectly labels a 'not rice' plant as 'rice'.\n",
    "    * A **low precision** (closer to 0.0) means that when the model predicts a plant is 'rice', it is often wrong. Many 'not rice' plants are being incorrectly classified as 'rice'.\n",
    "\n",
    "**Example Interpretation from Data:**\n",
    "\n",
    "If your model has a precision of 0.85 for the 'rice' label, it means that out of every 100 plants your model predicted as 'rice', 85 of them were actually rice, and 15 were something else (false alarms).\n",
    "\n",
    "### 2. Recall (Sensitivity or True Positive Rate): \"Of all the plants that were actually rice, how many did the model correctly identify?\"\n",
    "\n",
    "* **Formula:** $\\text{Recall} = \\frac{TP}{TP + FN}$\n",
    "* **Usefulness:** Recall is useful when you want to minimize **false negatives**. In other words, when it's important to identify as many actual positive instances as possible, even if it means having some false positives.\n",
    "* **Interpretation:**\n",
    "    * A **high recall** (closer to 1.0) means that the model is good at finding most of the actual 'rice' plants. It doesn't miss many of them.\n",
    "    * A **low recall** (closer to 0.0) means that the model misses many of the actual 'rice' plants, incorrectly classifying them as 'not rice'.\n",
    "\n",
    "**Example Interpretation from Data:**\n",
    "\n",
    "If your model has a recall of 0.92 for the 'rice' label, it means that out of every 100 plants that were actually rice, your model correctly identified 92 of them. It missed 8 actual rice plants.\n",
    "\n",
    "### 3. F1-Score: Finding the Balance Between Precision and Recall\n",
    "\n",
    "* **Formula:** $\\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "* **Usefulness:** The F1-score is the harmonic mean of precision and recall. It provides a single metric that balances both concerns. It's particularly useful when you have an imbalanced dataset (where one class has significantly more instances than others) or when both false positives and false negatives are important to consider.\n",
    "* **Interpretation:**\n",
    "    * A **high F1-score** (closer to 1.0) indicates a good balance between precision and recall. The model is performing well in both correctly identifying positive instances and minimizing false alarms and misses.\n",
    "    * A **low F1-score** (closer to 0.0) suggests that the model has a poor balance between precision and recall. It might have high precision but low recall (or vice versa), indicating a problem with the classification performance.\n",
    "\n",
    "**Example Interpretation from Data:**\n",
    "\n",
    "If your model has an F1-score of 0.88 for the 'rice' label, it suggests a relatively good balance between its ability to correctly predict rice and its ability to find all the actual rice plants.\n",
    "\n",
    "### How to Interpret from Your Overall Output:\n",
    "\n",
    "When you calculated the `accuracy`, `precision`, `recall`, and `f1_score` with `average='weighted'`, these metrics are calculated for each class (rice, banana, soybean, etc.) and then averaged, weighted by the number of true instances for each class. This gives you an overall sense of how well your model performs across all the different crop labels, taking into account any class imbalance in your test set.\n",
    "\n",
    "* **Accuracy:** Gives you the overall percentage of correctly classified instances. While easy to understand, it can be misleading on imbalanced datasets.\n",
    "* **Weighted Precision:** Tells you, on average (weighted by the prevalence of each class), how often the model's positive predictions were correct.\n",
    "* **Weighted Recall:** Tells you, on average (weighted by the prevalence of each class), what proportion of actual positive instances the model correctly identified.\n",
    "* **Weighted F1-score:** Provides a single, balanced measure of the model's performance across all classes, considering both precision and recall and accounting for class imbalance.\n",
    "\n",
    "By looking at these metrics together, you can get a comprehensive understanding of your model's strengths and weaknesses in classifying different crop types. For example, if you see a high precision but a lower recall for a specific crop, it means the model is very confident when it predicts that crop, but it might be missing some actual instances of that crop. The F1-score helps you see the overall trade-off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
